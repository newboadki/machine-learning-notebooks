{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Lab\n",
    "The purpose of this notebook is to experiment with different ways of solving the problem of text sentiment analysis, that is determining if a given sentence has a positive or negative fell to it.\n",
    "\n",
    "We'll compare the following: \n",
    "* A simple TensorFlow Linear regresion model.\n",
    "* An LSTM-based model.\n",
    "* A custom Linear regression model implementing gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [2 - Framing the problem](#2)\n",
    "    * [2.1 - Purpose](#2_1)\n",
    "    * [2.2 - Type of problem](#2_2)\n",
    "    * [2.3 - Logistic regression](#2_3)    \n",
    "    * [2.3.1 - Logistic regression and the sigmoid function](#2_3_1)\n",
    "* [3 - The data](#3)\n",
    "* [4 - Exploring the data](#4)\n",
    "* [5 - Processing the data](#5)\n",
    "    * [5.1 - Feature engineering](#5_1)\n",
    "    * [5.2 - Input processing and clean-up](#5_2)\n",
    "    * [5.3 - Data set split](#5_3)\n",
    "    * [5.4 - Extracting the features](#5_4)\n",
    "* [6 - Model Exploration](#6)\n",
    "    * [6.1 Logistic Regresion with TensorFlow](#6_1)\n",
    "        * [6.1.1 Doing some tests](#6_1_1)\n",
    "    * [6.2 LSTM-based Sentiment Analysis](#6_2)\n",
    "        * [6.2.1 Feature engineering](#6_2_1)\n",
    "        * [6.2.2 Model architecture](#6_2_2)\n",
    "        * [6.2.3 LSTM v1](#6_2_3)\n",
    "        * [6.2.4 LSTM v2](#6_2_4)\n",
    "            * [6.2.4.1 Avoiding overfitting](#6_2_1)\n",
    "            * [6.2.4.2 Results](#6_2_4_2)\n",
    "            * [6.2.4.3 Comparing the LSTM version with the LR baseline](#6_2_4_3)\n",
    "* [7 - Custom implementation a of Logistic regression model](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framing the problem<a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "## Purpose<a class=\"anchor\" id=\"2_1\"></a>\n",
    "Given a text sentence, in particular a tweet, we want to classify it as having a positive or negative sentiment. This will be used purely for statistical purposes. As a consequence, detecting abusive language is not a priority as this might required a specialized data set.\n",
    "\n",
    "## Type of problem<a class=\"anchor\" id=\"2_2\"></a>\n",
    "This can be solved with supervised and offline machine learning algorithms. Furthermore, this is a classification problem.\n",
    "\n",
    "## Logistic regression<a class=\"anchor\" id=\"2_3\"></a>\n",
    "Logistic regression is a statistical model to predict the probability of an event given a set of independent variables. \n",
    "$$ \\hat{y} = P(y=1 | x), x \\in   \\mathbb{R^n} $$\n",
    "\n",
    "It is usually used to categorize an input and it can be binary or multinomial. Therefore, it is a natural predictive model for binary classification problems such as sentiment analysis. \n",
    "\n",
    "### Logistic Regression and the Sigmoid function<a class=\"anchor\" id=\"2_3_1\"></a>\n",
    "\n",
    "Logistic regression takes a regular linear regression, and applies to it a sigmoid function.\n",
    "\n",
    "**Regression:**\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "\n",
    "**Logistic regression:**\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "\n",
    "\n",
    "# The data <a class=\"anchor\" id=\"3\"></a>\n",
    "NLTK's Twitter corpus currently contains a sample of 20k Tweets (named 'twitter_samples') retrieved from the Twitter Streaming API, together with another 10k which are divided according to sentiment into negative and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data <a class=\"anchor\" id=\"4\"></a>\n",
    "We can observe a few important characteristics of the input text. \n",
    "- Twitter handles contain specific characters and in most cases do not impact the sentiment of a tweet. We can safely remove them\n",
    "- Hash tags are preceeded by the pound symbol and can contain meaningul information. We should keep them.\n",
    "- They contain informal language, often enlarging words to express emotion or shortening them for brevity. This makes stemming a good tool for this problem.\n",
    "- They contain emojis, combination of punctuaction symbols that should be kept as carry a lot of meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "from utils import process_tweet, build_freqs\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "all_positive_count = len(all_positive_tweets)\n",
    "all_negative_count = len(all_negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5\"></a>\n",
    "# Processing the data\n",
    "\n",
    "<a class=\"anchor\" id=\"5_1\"></a>\n",
    "## Feature engineering\n",
    "The raw input is text, which we could tokenize and convert to index numbers of the word in the corpus vocabulary. This would probably work as the model could potentially learn that certain words appear whenerver the label is positive or negative.\n",
    "\n",
    "However, we can make things easier for the model by already condensing certain amount of information into the feature vectors. One of the most common approaches is to count frequencies of positive and negative words in a given tweet, since they have a clear impact on the sentiment of a tweet.\n",
    "\n",
    "<a class=\"anchor\" id=\"5_2\"></a>\n",
    "## Input processing and clean-up\n",
    "For the task of sentiment analysis we will perform the following operations. Notice that we are not converting the words into numbers. This is becaue of our decision to create a feature vector based on positive and negative frequency counts.\n",
    "\n",
    "- Remove stock market tickers like $GE\n",
    "- Remove old style retweet text \"RT\"\n",
    "- Remove hyperlinks    \n",
    "- Remove hashtag symbols, keeping the names\n",
    "- Remove stopwords\n",
    "- Remove punctuation, keeping emojis\n",
    "- Stem the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set split <a class=\"anchor\" id=\"5_3\"></a>\n",
    "We will use 80% of the samples for training, the rest for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into two pieces, one for training and one for testing (validation set) \n",
    "TRAIN_SPLIT = 0.8\n",
    "train_pos_count = int(all_positive_count * TRAIN_SPLIT)\n",
    "train_neg_count = int(all_negative_count * TRAIN_SPLIT)\n",
    "\n",
    "test_pos = all_positive_tweets[train_pos_count:]\n",
    "train_pos = all_positive_tweets[:train_pos_count]\n",
    "test_neg = all_negative_tweets[train_neg_count:]\n",
    "train_neg = all_negative_tweets[:train_neg_count]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)\n",
    "freqs = build_freqs(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features <a class=\"anchor\" id=\"5_4\"></a>\n",
    "\n",
    "For this we need two steps:\n",
    "- Count the number of times a word appears in a tweet labelled as positive and also as negative.\n",
    "- Represent each tweet as a feature vector with two of its components being the positive and negative counts of all its words.\n",
    "\n",
    "Our transformed inputs the models will work with from now on will be train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words\n",
    "        freqs: a dictionary with key: (word, label), value: count of word with label\n",
    "    Output: \n",
    "        feat_vector: a feature vector of dimension (1,3): [bias, pos_count, neg_count]\n",
    "    '''\n",
    "    word_l = process_tweet(tweet)\n",
    "    feat_vector = np.zeros(3) \n",
    "    feat_vector[0] = 1 # always set the bias s 1\n",
    "    \n",
    "    for word in word_l:        \n",
    "        feat_vector[1] += freqs.get((word, 1), 0) # inc. count for positive label\n",
    "        feat_vector[2] += freqs.get((word, 0), 0) # inc. count for negative label\n",
    "    \n",
    "    feat_vector = feat_vector[None, :]  # adding batch dimension for further processing\n",
    "\n",
    "    return feat_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    train_X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "test_X = np.zeros((len(test_x), 3))\n",
    "for i in range(len(test_x)):\n",
    "    test_X[i, :]= extract_features(test_x[i], freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model exploration <a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "## Logistic Regresion with TensorFlow <a class=\"anchor\" id=\"6_1\"></a>\n",
    "\n",
    "We start with a very simple model with one dense layer made up of one neuron.\n",
    "\n",
    "We can observe good accuracy results in both training and validation sets, with no signs of overfitting. The size of the data set is very small and not representative of a realistic problem setting. But for the purposes of comparing different implementations, we won't do more changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=((None, ) + train_X.shape), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), \n",
    "              loss='bce',\n",
    "              metrics=['accuracy']) # 1e-8\n",
    "history = model.fit(np.array(train_X),\n",
    "                    np.array(train_y),\n",
    "                    batch_size=1024,\n",
    "                    epochs=50,\n",
    "                    validation_data=(np.array(test_X), np.array(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# # == DRAWING THE ACCURACY == \n",
    "pyplot.plot(history.history['accuracy'][1:], label='train acc')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Accuracy')\n",
    "pyplot.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/lr-tf-acc.PNG\" alt=\"LR TensorFlow accuracy\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == DRAWING THE LOSS == \n",
    "from matplotlib import pyplot \n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train-val') \n",
    "pyplot.plot(history.history['val_loss'], label='test-val') \n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Loss')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/lr-tf-loss.PNG\" alt=\"LR TensorFlow loss\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(np.array(test_X), np.array(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing some tests <a class=\"anchor\" id=\"6_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in ['she is very anoying and selfish', 'good job', 'I was happy after our first talk', 'I was undecided after our first talk']:\n",
    "    feats = extract_features(tweet, freqs)\n",
    "    print( '%s -> %f' % (tweet, model.predict(np.array(feats))))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-based Sentiment Analysis <a class=\"anchor\" id=\"6_2\"></a>\n",
    "\n",
    "### Feature engineering <a class=\"anchor\" id=\"6_2_1\"></a>\n",
    "In order to solve the problem with a recurrent neural network (RNN), we need to rethink how we input data into the model. RNNs expect a sequence of values (also called time steps) and at each step the previous state and the new value are used to update the internal state.\n",
    "\n",
    "Therefore, using a frequency count based metric doesn't seem natural for this particular implementation. What we will do intead is to tokenize each word by representing them with their index in the courpus vocabulary.\n",
    "\n",
    "Additionally, RNN expect a fixed-length sequence as the input. Since tweets can vary in length we need to pad them to guarantee they have the same length. We will choose post zero padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def process_inputs(train_x, test_x, max_length=10, vocab_size=1000):\n",
    "    train_x_processsed = []\n",
    "    test_x_processsed = []\n",
    "\n",
    "    for tweet in train_x:\n",
    "        p_tweet = process_tweet(tweet)\n",
    "        p_tweet_joined = ' '.join(p_tweet)    \n",
    "        train_x_processsed.append(p_tweet_joined)\n",
    "\n",
    "    for tweet in test_x:\n",
    "        p_tweet = ' '.join(process_tweet(tweet))\n",
    "        test_x_processsed.append(p_tweet)\n",
    "\n",
    "    # Create Tokenizer\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\") # num_words=1000,\n",
    "    tokenizer.fit_on_texts(train_x_processsed)\n",
    "\n",
    "    # Padding\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_x_processsed)\n",
    "    train_padded_sequences = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x_processsed)\n",
    "    test_padded_sequences = pad_sequences(test_sequences, padding='post', maxlen=max_length)\n",
    "    \n",
    "    return train_sequences, train_padded_sequences, test_sequences, test_padded_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture <a class=\"anchor\" id=\"6_2_2\"></a>\n",
    "We will try an initial configuration where we use the full vocabulary to train the network. In addition to that, we will select ceratain amount of complexity for the dimension of the LSTM, embeddings and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == BUILD THE MODEL ==\n",
    "\n",
    "def lstm_model_1(vocab_size=1000, embedding_dim=8, lstm_dim=8, dense_dim=12, max_length=10):\n",
    "    # Model Definition with LSTM\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        keras.layers.LSTM(lstm_dim),\n",
    "        keras.layers.Dense(dense_dim, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Set the training parameters\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Print the model summary\n",
    "    model.summary()  \n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Utility\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM v1 <a class=\"anchor\" id=\"6_2_3\"></a>\n",
    "We will try an initial configuration where we use the full vocabulary to train the network. In addition to that, we will select ceratain amount of complexity for the dimension of the LSTM, embeddings and dense layers.\n",
    "\n",
    "#### Results <a class=\"anchor\" id=\"6_2_3_1\"></a>\n",
    "The Accuracy achieved is 0.67 and the charts do not show a nice stabilizing curve for the loss and accuracy. Since overfitting is a common problem for LSTM networks, we'll try to apply counter measures in the next version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "vocab_size = 9000\n",
    "train_sequences, train_padded_sequences, test_sequences, test_padded_sequences = process_inputs(train_x, test_x, max_length=max_length, vocab_size=vocab_size)\n",
    "model_1 = lstm_model_1(vocab_size=vocab_size, embedding_dim=16, lstm_dim=64, dense_dim=32, max_length=max_length)\n",
    "history_lstm = model_1.fit(train_padded_sequences, train_y, epochs=10, validation_data=(test_padded_sequences, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy and loss history\n",
    "plot_graphs(history_lstm, 'accuracy')\n",
    "plot_graphs(history_lstm, 'loss')\n",
    "\n",
    "# Repeat model evaluation to see it match graph\n",
    "model_1.evaluate(test_padded_sequences, test_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/lstm-v1.PNG\" alt=\"LSTM-based architecture\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM v2 <a class=\"anchor\" id=\"6_2_4\"></a>\n",
    "\n",
    "#### Avoiding overfitting <a class=\"anchor\" id=\"6_2_4_1\"></a>\n",
    "- Reduce the vocabulary size from 9008 to 1000. This is effectively reducing the complexity of the model, which is a typical measure against overfitting. This can cause a performance decrease though, as the model won't be able to learn from those unknown words.\n",
    "- Define a shorter max_length to prevent the model from traying to learn from a large tail of zeros in each sentence\n",
    "- Reduce the complexity of the model (number of neurons inside an LSTM, number of neurons in the dense layer, reduce the embedding layer's dimensionality)\n",
    "- Add dropout layers. Excluding certain neurons from some of the training steps, helps prevent the model from overfitting the data set. Most of the improvements could be achieved only by modifying the hyperparameters. However, the dropout layer achieved an increase of accuracy, while delaying the increase in the loss, thought of in this context as the confidence in the result.\n",
    "- From the charts, we can see that the val_loss although much closer to a stable horizontal line, increases with the number of epochs. Therefore in this case, training for longer, would not be beneficial.\n",
    "\n",
    "#### Results <a class=\"anchor\" id=\"6_2_4_2\"></a>\n",
    "- The accuracy in the validation set increased to 0.75\n",
    "- The charts also displayed more common curves for loss and accuracy for LSTMs.\n",
    "\n",
    "#### Comparing the LSTM version with the LR baseline <a class=\"anchor\" id=\"6_2_4_3\"></a>\n",
    "Although we were able to decrease the overfitting and improve the performance on the training set, we are still far away from the baseline model's results. A few considerations are layed out below:\n",
    "- The size of the training set is 8000 samples, definitely small and prone to overfitting. Increasing it should be an action moving forward.\n",
    "- Secondly, given the simplicity of the problem, and the amount of information encoded in the frequency count based features, it seems natural that an sequence model approach could draw worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_2(vocab_size=1000, embedding_dim=8, lstm_dim=8, dense_dim=12, max_length=10):\n",
    "    # Model Definition with LSTM\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.LSTM(lstm_dim),\n",
    "        keras.layers.Dense(dense_dim, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Set the training parameters\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Print the model summary\n",
    "    model.summary()  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "vocab_size = 1000\n",
    "train_sequences, train_padded_sequences, test_sequences, test_padded_sequences = process_inputs(train_x, test_x, max_length=max_length, vocab_size=vocab_size)\n",
    "model_2 = lstm_model_2(vocab_size=vocab_size, embedding_dim=8, lstm_dim=8, dense_dim=12, max_length=max_length)\n",
    "history_lstm = model_2.fit(train_padded_sequences, train_y, epochs=10, validation_data=(test_padded_sequences, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy and loss history\n",
    "plot_graphs(history_lstm, 'accuracy')\n",
    "plot_graphs(history_lstm, 'loss')\n",
    "\n",
    "# Repeat model evaluation to see it match graph\n",
    "model_2.evaluate(test_padded_sequences, test_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/lstm-v2.PNG\" alt=\"LSTM v2 accuracy and loss\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY WITH YOUR OWN TWEETS\n",
    "my_tweet = \"\"\n",
    "p_my_tweet = process_tweet(my_tweet)\n",
    "seqs = tokenizer.texts_to_sequences([p_my_tweet])\n",
    "train_padded_seqs = pad_sequences(seqs, padding='post', maxlen=max_length)\n",
    "r = model_lstm.predict(train_padded_seqs)\n",
    "result = r.flatten()[0] > 0.5\n",
    "if result:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom implementation a of Logistic regression model <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    \n",
    "    return 1 / (1 + np.exp(-1 * np.array(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "## Cost function and Gradient\n",
    "\n",
    "The cost function used for logistic regression is the average of the log loss across all training examples:\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
    "* $m$ is the number of training examples\n",
    "* $y^{(i)}$ is the actual label of training example 'i'.\n",
    "* $h(z^{(i)})$ is the model's prediction for the training example 'i'.\n",
    "\n",
    "The loss function for a single training example is\n",
    "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the weights\n",
    "\n",
    "To update your weight vector $\\theta$, you will apply gradient descent to iteratively improve your model's predictions.  \n",
    "The gradient of the cost function $J$ with respect to one of the weights $\\theta_j$ is:\n",
    "\n",
    "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x^{(i)}_j \\tag{5}$$\n",
    "* 'i' is the index across all 'm' training examples.\n",
    "* 'j' is the index of the weight $\\theta_j$, so $x^{(i)}_j$ is the feature associated with weight $\\theta_j$\n",
    "\n",
    "* To update the weight $\\theta_j$, we adjust it by subtracting a fraction of the gradient determined by $\\alpha$:\n",
    "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
    "* The learning rate $\\alpha$ is a value that we choose to control how big a single update will be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing gradientDescent\n",
    "Cost function:\n",
    "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
    "\n",
    "Updating the weights:\n",
    "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "\n",
    "    # Number of rows in matrix x\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):        \n",
    "        z = np.dot(x, theta) # x⋅z\n",
    "        h = sigmoid(z)\n",
    "        J = float(-1 / m) * (np.dot(np.transpose(y), np.log(h)) + np.dot(np.transpose(1 - y), np.log(1 - h)))\n",
    "        theta = theta - alpha/m * np.dot(np.transpose(x), h-y)\n",
    "\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your Model\n",
    "\n",
    "To train the model:\n",
    "* Stack the features for all training examples into a matrix X. \n",
    "* Call `gradientDescent`, which you've implemented above.\n",
    "\n",
    "This section is given to you.  Please read it for understanding and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J, theta = gradientDescent(train_X, train_y, np.zeros((3, 1)), 1e-9, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the custom Logistic Regression version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    x = extract_features(tweet, freqs)\n",
    "    z = np.dot(x, theta)\n",
    "    y_pred = sigmoid(z)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to test your function\n",
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        test_x: a list of tweets\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    Output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"\n",
    "    \n",
    "    y_hat = []\n",
    "    m = len(test_x)\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1.0)\n",
    "        else:\n",
    "            y_hat.append(0.0)\n",
    "\n",
    "    y_hat_array = np.array(y_hat)\n",
    "    t_y_array = np.reshape(test_y, m)    \n",
    "    accuracy = 1/m * np.sum(y_hat_array == t_y_array)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change the tweet below\n",
    "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_nlp-c1-w1)",
   "language": "python",
   "name": "conda_nlp-c1-w1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
